{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8e47d03-cb7a-40e5-8bef-a2154b34abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from minsearch import AppendableIndex\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e84263b-88f6-40e5-aa8e-f271978b205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_URL = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09e9b24-c79b-41ba-86da-7f7d8dbb2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.get(DOCS_URL) as docs_resp:\n",
    "    if docs_resp.status_code == 200:\n",
    "        docs_raw = docs_resp.json()\n",
    "        documents = []\n",
    "        for course in docs_raw:\n",
    "            course_name = course['course']\n",
    "            for doc in course['documents']:\n",
    "                doc['course'] = course_name\n",
    "                documents.append(doc)\n",
    "    else:\n",
    "        print(f\"\"\"Documents could not be fetched due to status code \n",
    "        {docs_resp.status_code} and issue being: \n",
    "        {docs_resp.reason}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5fd9c3d6-bdcf-4c1f-9e3e-611600151305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexMinsearch:\n",
    "    def __init__(self, documents: list[dict], text_fields: list=None, keyword_fields: list=None):\n",
    "        self.documents = documents\n",
    "        self.text_fields = text_fields\n",
    "        self.keyword_fields = keyword_fields\n",
    "        self.index = self.index_documents()\n",
    "\n",
    "    def index_documents(self):\n",
    "        index = AppendableIndex(\n",
    "        text_fields=self.text_fields,\n",
    "        keyword_fields=self.keyword_fields\n",
    "        )\n",
    "        index.fit(docs=self.documents)\n",
    "        return index\n",
    "\n",
    "class SearchMinsearch:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        \n",
    "    def search_query(self, query: str=\"\", results: int=5, filter_dict: dict={}):\n",
    "        if query:\n",
    "            if len(query) > 5:\n",
    "                results = self.index.search(\n",
    "                    query=query,\n",
    "                    filter_dict=filter_dict,\n",
    "                    num_results=results,\n",
    "                    output_ids=True)\n",
    "            else:\n",
    "                print(\"Minimum number of characters need to be more than 10\")\n",
    "                return None\n",
    "        return results\n",
    "\n",
    "class OpenAIClient:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def llm(self, prompt: str=\"\"):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = 'gpt-4o-mini',\n",
    "            messages = [{\"role\": \"user\",\n",
    "                         \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            seed=42\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb874e-4294-4d01-8a2e-6ad2f452fe7d",
   "metadata": {},
   "source": [
    "# Traditional Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d297ce5f-6572-470d-a789-b66190fa5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fields=[\"text\", \"section\", \"question\"]\n",
    "keyword_fields=[\"course\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "83256999-736f-41b5-9118-6af0077ccf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_search = IndexMinsearch(\n",
    "    documents=documents,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields)\n",
    "\n",
    "search = SearchMinsearch(\n",
    "    index=index_search.index)\n",
    "open_ai_client = OpenAIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f16fd69e-e654-48a2-8693-697113bd3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When does the course start?\"\n",
    "filter_dict = {\"course\": \"data-engineering-zoomcamp\"} if\"course\" in index_search.keyword_fields else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1940dc35-78ec-468f-9c0f-c09e9cd63d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.search_query(\n",
    "    query=query,\n",
    "    filter_dict=filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a3f6b3a-13f5-4d60-bc5f-0a8ddc48784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7df1394e-abe3-4949-a5c6-b46172b3c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query: str, search_results: list[dict]):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5251efec-06b1-4bd3-ab60-d76d533f59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query: str, filter_dict: dict):\n",
    "    search_results = search.search_query(query=query, filter_dict=filter_dict)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = open_ai_client.llm(prompt=prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b0bba6a5-4a8f-4455-899b-581a3f773735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, but there is no information provided in the CONTEXT regarding \"WASD\" in \"llm rag.\" Please provide more details or check the FAQ database for relevant information.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\n",
    "    query=\"What is WASD in llm rag\",\n",
    "    filter_dict=filter_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a2f47-0857-41ee-8409-038b2a510ce0",
   "metadata": {},
   "source": [
    "# Agentic Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e069419a-5a13-48ae-9cbb-ce5f21c8138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = \"\"\"You are an Agentic FAQ Assistant. Your job is to answer user questions using:\n",
    "1. Retrieved FAQ context from MinSearch (authoritative)\n",
    "2. If no relevant FAQ context exists, use your own general reasoning and knowledge,\n",
    "   especially when the iteration limit is reached.\n",
    "\n",
    "You operate with short iterative steps. You remember:\n",
    "- previous user queries\n",
    "- your own previous final answers\n",
    "- previous retrieval/search attempts\n",
    "- iteration count for the current query\n",
    "\n",
    "#############################\n",
    "## CORE BEHAVIOUR RULES\n",
    "#############################\n",
    "\n",
    "1. Always prefer FAQ knowledge over your own knowledge.\n",
    "   If FAQ context is relevant, treat it as the correct source of truth.\n",
    "\n",
    "2. If FAQ context is empty, low-confidence, or irrelevant:\n",
    "   - If current iteration number {iteration_count} < {max_iterations} iterations:\n",
    "       perform a MinSearch lookup with topic expansion.\n",
    "   - If current iteration number {iteration_count} == {max_iterations} iterations:\n",
    "       DO NOT search again; answer using your own internal knowledge.\n",
    "\n",
    "3. Never hallucinate FAQ entries or contradict retrieved FAQ context.\n",
    "\n",
    "4. Keep answers concise unless the user requests detail.\n",
    "\n",
    "5. Maintain consistency with wording used in the FAQ database.\n",
    "\n",
    "6. Do NOT reveal internal chain-of-thought, retrieval decisions,\n",
    "   topic expansions, or reasoning. Only reveal the final answer.\n",
    "\n",
    "7. If a similar question exists in session_history:\n",
    "   Reuse the prior answer unless new FAQ context changes the meaning.\n",
    "\n",
    "#############################\n",
    "## TOPIC EXPANSION FOR MINSEARCH\n",
    "#############################\n",
    "\n",
    "Before performing a search action:\n",
    "- Expand the user query with 2–4 additional terms:\n",
    "  • synonyms\n",
    "  • domain-specific variations\n",
    "  • common FAQ phrasing\n",
    "- Only include terms logically related to the user’s words.\n",
    "- Do NOT invent new entities, products, or facts.\n",
    "\n",
    "Format the MinSearch query as:\n",
    "\"<original user query> | <topic1> | <topic2> | <topic3>\"\n",
    "\n",
    "This expansion is mandatory for all search actions.\n",
    "\n",
    "#############################\n",
    "## DECISION PROCESS\n",
    "#############################\n",
    "\n",
    "For each user turn, you will be provided:\n",
    "- question\n",
    "- session_history\n",
    "- iteration_count\n",
    "- search_queries\n",
    "- context\n",
    "\n",
    "Follow these rules:\n",
    "\n",
    "1. If FAQ context is relevant → answer with source=\"faq\".\n",
    "2. If FAQ context is empty, low-confidence, or irrelevant:\n",
    "   - If current iteration number {iteration_count} < {max_iterations} iterations:\n",
    "       perform a MinSearch lookup with topic expansion.\n",
    "   - If current iteration number {iteration_count} == {max_iterations} iterations:\n",
    "       DO NOT search again; answer using your own internal knowledge.\n",
    "\n",
    "#############################\n",
    "## OUTPUT RULES\n",
    "#############################\n",
    "\n",
    "Respond strictly in the JSON formats below.\n",
    "\n",
    "### When more retrieval is needed:\n",
    "{{\n",
    "  \"action\": \"SEARCH\",\n",
    "  \"reasoning\": \"<add your reasoning here>\",\n",
    "  \"search_query\": \"original_query | topic1 | topic2 | topic3\"\n",
    "}}\n",
    "\n",
    "### When a final answer is available:\n",
    "{{\n",
    "  \"action\": \"ANSWER\",\n",
    "  \"source\": \"faq\",\n",
    "  \"answer\": \"<your answer>\"\n",
    "}}\n",
    "\n",
    "### If no context is found after max iterations, use your own knowledge to answer the question\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{session_history}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\n",
    "\n",
    "Never output anything else.\n",
    "Do not include explanations, chain-of-thought, or debugging notes.\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfe57f94-b89d-4fbf-8679-f8f3593f3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchMinsearch:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        \n",
    "    def search_query(self, query: str=\"\", results: int=5, filter_dict: dict={}):\n",
    "        if query:\n",
    "            if len(query) > 5:\n",
    "                results = self.index.search(\n",
    "                    query=query,\n",
    "                    filter_dict=filter_dict,\n",
    "                    num_results=results,\n",
    "                    output_ids=True)\n",
    "            else:\n",
    "                print(\"Minimum number of characters need to be more than 10\")\n",
    "                return None\n",
    "        return results\n",
    "\n",
    "class OpenAIClient:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def llm(self, prompt: str=\"\"):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = 'gpt-4o-mini',\n",
    "            messages = [{\"role\": \"user\",\n",
    "                         \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            seed=42\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b010803c-c9e6-4a42-a3ad-ea1c21cb2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"EMPTY\"\n",
    "query = \"when does the engineering zoomcamp start?\"\n",
    "search_queries = []\n",
    "session_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5a1ea857-1ecc-4d52-8b88-a8bf26b47931",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = qa_prompt.format(question=query,\n",
    "                          context=context,\n",
    "                          iteration_count=0,\n",
    "                          max_iterations=3,\n",
    "                         search_queries=search_queries,\n",
    "                         session_history=session_history).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1be7b69a-4b35-4db2-83b5-6ca2c7f613c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an Agentic FAQ Assistant. Your job is to answer user questions using:\n",
      "1. Retrieved FAQ context from MinSearch (authoritative)\n",
      "2. If no relevant FAQ context exists, use your own general reasoning and knowledge,\n",
      "   especially when the iteration limit is reached.\n",
      "\n",
      "You operate with short iterative steps. You remember:\n",
      "- previous user queries\n",
      "- your own previous final answers\n",
      "- previous retrieval/search attempts\n",
      "- iteration count for the current query\n",
      "\n",
      "#############################\n",
      "## CORE BEHAVIOUR RULES\n",
      "#############################\n",
      "\n",
      "1. Always prefer FAQ knowledge over your own knowledge.\n",
      "   If FAQ context is relevant, treat it as the correct source of truth.\n",
      "\n",
      "2. If FAQ context is empty, low-confidence, or irrelevant:\n",
      "   - If current iteration number 0 < 3 iterations:\n",
      "       perform a MinSearch lookup with topic expansion.\n",
      "   - If current iteration number 0 == 3 iterations:\n",
      "       DO NOT search again; answer using your own internal knowledge.\n",
      "\n",
      "3. Never hallucinate FAQ entries or contradict retrieved FAQ context.\n",
      "\n",
      "4. Keep answers concise unless the user requests detail.\n",
      "\n",
      "5. Maintain consistency with wording used in the FAQ database.\n",
      "\n",
      "6. Do NOT reveal internal chain-of-thought, retrieval decisions,\n",
      "   topic expansions, or reasoning. Only reveal the final answer.\n",
      "\n",
      "7. If a similar question exists in session_history:\n",
      "   Reuse the prior answer unless new FAQ context changes the meaning.\n",
      "\n",
      "#############################\n",
      "## TOPIC EXPANSION FOR MINSEARCH\n",
      "#############################\n",
      "\n",
      "Before performing a search action:\n",
      "- Expand the user query with 2–4 additional terms:\n",
      "  • synonyms\n",
      "  • domain-specific variations\n",
      "  • common FAQ phrasing\n",
      "- Only include terms logically related to the user’s words.\n",
      "- Do NOT invent new entities, products, or facts.\n",
      "\n",
      "Format the MinSearch query as:\n",
      "\"<original user query> | <topic1> | <topic2> | <topic3>\"\n",
      "\n",
      "This expansion is mandatory for all search actions.\n",
      "\n",
      "#############################\n",
      "## DECISION PROCESS\n",
      "#############################\n",
      "\n",
      "For each user turn, you will be provided:\n",
      "- question\n",
      "- session_history\n",
      "- iteration_count\n",
      "- search_queries\n",
      "- context\n",
      "\n",
      "Follow these rules:\n",
      "\n",
      "1. If FAQ context is relevant → answer with source=\"faq\".\n",
      "2. If FAQ context is empty, low-confidence, or irrelevant:\n",
      "   - If current iteration number 0 < 3 iterations:\n",
      "       perform a MinSearch lookup with topic expansion.\n",
      "   - If current iteration number 0 == 3 iterations:\n",
      "       DO NOT search again; answer using your own internal knowledge.\n",
      "\n",
      "#############################\n",
      "## OUTPUT RULES\n",
      "#############################\n",
      "\n",
      "Respond strictly in the JSON formats below.\n",
      "\n",
      "### When more retrieval is needed:\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"<add your reasoning here>\",\n",
      "  \"search_query\": \"original_query | topic1 | topic2 | topic3\"\n",
      "}\n",
      "\n",
      "### When a final answer is available:\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"source\": \"faq\",\n",
      "  \"answer\": \"<your answer>\"\n",
      "}\n",
      "\n",
      "### If no context is found after max iterations, use your own knowledge to answer the question\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "when does the engineering zoomcamp start?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "[]\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "[]\n",
      "</PREVIOUS_ACTIONS>\n",
      "\n",
      "\n",
      "Never output anything else.\n",
      "Do not include explanations, chain-of-thought, or debugging notes.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3c7ec8b5-de85-4312-99e5-e804121374e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open_ai_client.llm(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "356a0236-393a-477f-8e6b-481374dca2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = []\n",
    "if json.loads(result)['action'] == 'SEARCH':\n",
    "    for topic in json.loads(result)['search_query'].split(\"|\"):\n",
    "        sr = search.search_query(query=topic.strip(), filter_dict=filter_dict)\n",
    "        search_queries.append(topic.strip())\n",
    "        search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "00846f90-baa1-468e-9acb-3d2e997afd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(sequence: list[dict]) -> list[dict]:\n",
    "    seen = set()\n",
    "    results = []\n",
    "    for i in sequence:\n",
    "        if i['_id'] in seen:\n",
    "            continue\n",
    "        else:\n",
    "            seen.add(i['_id'])\n",
    "            results.append(i)\n",
    "    return results\n",
    "\n",
    "def build_context(search_results: list[dict]):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c1dbce4f-0ba4-4f3d-ad09-75df4f4d91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dedup(search_results)\n",
    "context = build_context(search_results=search_results)\n",
    "iteration_count=1\n",
    "max_iterations=3\n",
    "session_history.append(json.loads(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ec8d772e-13b9-4262-b58a-4747dd39fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = qa_prompt.format(question=query,\n",
    "                 context=context,\n",
    "                 iteration_count=iteration_count,\n",
    "                 max_iterations=max_iterations,\n",
    "                 search_queries=\"\\n\".join(search_queries),\n",
    "                 session_history=\"\\n\".join([json.dumps(a) for a in session_history])\n",
    "                         ).strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3cbbd632-075e-4d84-a19c-4dda2c5e112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open_ai_client.llm(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "019d5b71-dd64-43b2-9d66-afb790041b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ed89fe00-cdf8-43bc-8c1b-9113e9468d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agentic_rag(query: str):\n",
    "    start_time = time.perf_counter()\n",
    "    context = \"EMPTY\"\n",
    "    search_queries = []\n",
    "    session_history = []\n",
    "    iteration_count = 0\n",
    "    max_iterations = 3\n",
    "    \n",
    "    while True:\n",
    "        prompt = qa_prompt.format(question=query,\n",
    "                                  context=context,\n",
    "                                  iteration_count=iteration_count,\n",
    "                                  max_iterations=max_iterations,\n",
    "                                  search_queries=\"\\n\".join(search_queries),\n",
    "                                  session_history=\"\\n\".join([json.dumps(a) for a in session_history])\n",
    "                                 ).strip()\n",
    "        result = open_ai_client.llm(prompt=prompt)\n",
    "        session_history.append(json.loads(result))\n",
    "        search_results = []\n",
    "        if json.loads(result)['action'] == 'SEARCH':\n",
    "            for topic in json.loads(result)['search_query'].split(\"|\"):\n",
    "                sr = search.search_query(query=topic.strip(), filter_dict=filter_dict)\n",
    "                search_queries.append(topic.strip())\n",
    "                search_results.extend(sr)\n",
    "            search_results = dedup(search_results)\n",
    "            context = build_context(search_results=search_results)\n",
    "            search_queries = list(set(search_queries))\n",
    "            iteration_count += 1\n",
    "        else:\n",
    "            break\n",
    "        if iteration_count >= 4:\n",
    "            break\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken {elapsed_time:.4f} seconds\")\n",
    "    print(f\"Iteration number {iteration_count}\")\n",
    "    return json.loads(result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e507968d-0c31-4c36-bfcf-04bd9f60c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 5.2198 seconds\n",
      "Iteration number 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"The Data Engineering Zoomcamp generally runs from January to April each year, but you can complete it at your own pace if you're not pursuing certification.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agentic_rag(\"How long will it take to finish data engineering zoomcamp?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab24947-fc23-4daf-88e8-0028a9e0e7a4",
   "metadata": {},
   "source": [
    "# Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8b2befcf-d55e-42ef-934e-1ae3fbd678a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_search(query: str, search, filter_dict):\n",
    "\n",
    "    results = search.search_query(\n",
    "        query=query,\n",
    "        filter_dict=filter_dict)\n",
    "\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "abf88e3e-20a1-4d7f-a705-3d13146f44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"min_search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\", \"search\", \"filter_dict\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0af7bcef-35c5-4624-88fb-4568484bc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "    if function_name == \"min_search\":\n",
    "        arguments[\"search\"] =  search\n",
    "        arguments[\"filter_dict\"] = filter_dict\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dba8bd16-1ebe-4e10-9cbe-6547f2d882b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"How to do well in module 1\"}', call_id='call_cSdyyO2NnB4OA7xdQ7WFv82R', name='min_search', type='function_call', id='fc_093bfc4ea782c01f0069268fd3ec788198840fb7275bd26fd4', status='completed')]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a87e2d95-b438-4763-975b-1c42411c4814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'function_call_output', 'call_id': 'call_cSdyyO2NnB4OA7xdQ7WFv82R', 'output': '[\\n  {\\n    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 322\\n  },\\n  {\\n    \"text\": \"Error raised during the jupyter notebook\\\\u2019s cell execution:\\\\nengine = create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\').\\\\nSolution: Need to install Python module \\\\u201cpsycopg2\\\\u201d. Can be installed by Conda or pip.\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named \\'psycopg2\\'.\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 125\\n  },\\n  {\\n    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\\n    \"section\": \"Module 5: pyspark\",\\n    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 323\\n  },\\n  {\\n    \"text\": \"Issue:\\\\ne\\\\u2026\\\\nSolution:\\\\npip install psycopg2-binary\\\\nIf you already have it, you might need to update it:\\\\npip install psycopg2-binary --upgrade\\\\nOther methods, if the above fails:\\\\nif you are getting the \\\\u201c ModuleNotFoundError: No module named \\'psycopg2\\' \\\\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\\\nFirst uninstall the psycopg package\\\\nThen update conda or pip\\\\nThen install psycopg again using pip.\\\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\\n    \"section\": \"Module 1: Docker and Terraform\",\\n    \"question\": \"Postgres - ModuleNotFoundError: No module named \\'psycopg2\\'\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 112\\n  },\\n  {\\n    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\\n    \"section\": \"Module 4: analytics engineering with dbt\",\\n    \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\",\\n    \"course\": \"data-engineering-zoomcamp\",\\n    \"_id\": 299\\n  }\\n]'}\n"
     ]
    }
   ],
   "source": [
    "for call in response.output:\n",
    "    print(do_call(call))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "af859808-9eb4-4c27-8d36-59006293f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "calls = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "01dd6bb3-5dfb-4fab-95aa-27fa7f45ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for call in calls:\n",
    "    result = do_call(call)\n",
    "    chat_messages.append(call)\n",
    "    chat_messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "87f1c54f-8413-4b4c-a55d-c45452eb91be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_0ee23314897fc0030069278e2076ac8199980f831e0a6fee07', content=[ResponseOutputText(annotations=[], text='To excel in Module 1 of your course, here\\'s a summary of key tips and any relevant issues others have encountered:\\n\\n1. **Understand the Prerequisites**: Ensure you have the necessary tools installed, such as Docker and PostgreSQL. If you encounter problems with modules (e.g., `psycopg2`), you can resolve them by running the following commands:\\n   - Install with pip: \\n     ```bash\\n     pip install psycopg2-binary\\n     ```\\n   - If issues persist, update:\\n     ```bash\\n     pip install psycopg2-binary --upgrade\\n     ```\\n\\n2. **Set Up Your Environment**:\\n   - Verify that your Python environment is configured properly. If you\\'re getting \"ModuleNotFoundError,\" it may indicate that libraries are not installed correctly or paths are not set.\\n   - Ensure that PostgreSQL is installed if you encounter `pg_config not found`.\\n\\n3. **Utilize Resources**: Follow along with Docker setups and other instructions provided in the course materials. If you face errors, they may often be resolved by consulting the documentation or looking for community solutions.\\n\\n4. **Practice Regularly**: Engage with the coursework material consistently. Repetitive practice helps solidify your understanding of the concepts.\\n\\n5. **Seek Help When Stuck**: If you run into roadblocks, don\\'t hesitate to ask for help either from peers or during Q&A sessions. Common issues usually have resolutions already discussed in forums or FAQs.\\n\\n6. **Hands-On Experience**: Implement the concepts learned through hands-on projects or exercises mentioned in the module to reinforce your understanding.\\n\\nBy following these tips and addressing any common issues others have faced, you should be well positioned to succeed in Module 1. If you have more specific concerns, feel free to ask!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6c871906-199c-47aa-869e-80e18fff6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "To excel in Module 1 of your course, here's a summary of key tips and any relevant issues others have encountered:\n",
      "\n",
      "1. **Understand the Prerequisites**: Ensure you have the necessary tools installed, such as Docker and PostgreSQL. If you encounter problems with modules (e.g., `psycopg2`), you can resolve them by running the following commands:\n",
      "   - Install with pip: \n",
      "     ```bash\n",
      "     pip install psycopg2-binary\n",
      "     ```\n",
      "   - If issues persist, update:\n",
      "     ```bash\n",
      "     pip install psycopg2-binary --upgrade\n",
      "     ```\n",
      "\n",
      "2. **Set Up Your Environment**:\n",
      "   - Verify that your Python environment is configured properly. If you're getting \"ModuleNotFoundError,\" it may indicate that libraries are not installed correctly or paths are not set.\n",
      "   - Ensure that PostgreSQL is installed if you encounter `pg_config not found`.\n",
      "\n",
      "3. **Utilize Resources**: Follow along with Docker setups and other instructions provided in the course materials. If you face errors, they may often be resolved by consulting the documentation or looking for community solutions.\n",
      "\n",
      "4. **Practice Regularly**: Engage with the coursework material consistently. Repetitive practice helps solidify your understanding of the concepts.\n",
      "\n",
      "5. **Seek Help When Stuck**: If you run into roadblocks, don't hesitate to ask for help either from peers or during Q&A sessions. Common issues usually have resolutions already discussed in forums or FAQs.\n",
      "\n",
      "6. **Hands-On Experience**: Implement the concepts learned through hands-on projects or exercises mentioned in the module to reinforce your understanding.\n",
      "\n",
      "By following these tips and addressing any common issues others have faced, you should be well positioned to succeed in Module 1. If you have more specific concerns, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "59ff59b3-84d5-4720-bcd1-3b8524dbc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        \"question\": question,\n",
    "        \"text\": answer,\n",
    "        \"section\": \"user added\",\n",
    "        \"course\": \"data-engineering-zoomcamp\"\n",
    "    }\n",
    "    index_search.index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2fa63d01-436d-44f9-9397-c1011cb7de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5d7ac712-283c-48de-9173-c68e29840645",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, add_entry_description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5b19cf96-2d03-4728-9c91-d9dc3ba83283",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests, which means if you look up \n",
    "something in FAQ, convert the student question into multiple queries.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "87e8fadb-2285-4fc6-9f9f-8091815cb5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you wanna know How to do well in module 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To excel in Module 1 of the course, here are some essential tips:\n",
      "\n",
      "1. **Familiarize Yourself with Docker and Terraform**: Understanding the foundations of Docker and Terraform is key. Make sure to explore their official documentation and tutorials.\n",
      "\n",
      "2. **Install Required Libraries**: Ensure that any necessary libraries are correctly installed, especially `psycopg2` if you're working with PostgreSQL. For example, you can use:\n",
      "   ```\n",
      "   pip install psycopg2-binary\n",
      "   ```\n",
      "\n",
      "3. **Practice Hands-On**: Implement the concepts as you learn them. Spin up Docker containers and use Terraform to manage any configurations or deployments.\n",
      "\n",
      "4. **Check Your Code**:\n",
      "   - If you encounter errors (like \"ModuleNotFoundError\"), double-check your installations.\n",
      "   - Make sure to run your code in the correct environment (e.g., Jupyter notebook).\n",
      "\n",
      "5. **Engage with Peers**: If you have questions, discuss them within your course community or with classmates. Collaboration often leads to better understanding.\n",
      "\n",
      "6. **Utilize Office Hours**: If available, take advantage of the instructor's office hours to clarify complex topics.\n",
      "\n",
      "7. **Review Past Lectures and Assignments**: Make sure to revisit the materials, as they can reinforce your learning.\n",
      "\n",
      "8. **Stay Organized**: Keep your notes and folders organized for easy reference when studying for assessments.\n",
      "\n",
      "By applying these strategies and staying proactive in your learning, you can maximize your chances of achieving great results in Module 1.\n",
      "\n",
      "Would you like more specific information on any particular topic covered in Module 1?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you wanna know Lets add this to faq database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information has been successfully added to the FAQ database. \n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask! Would you like to explore another topic?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you wanna know stop\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"What do you wanna know\")\n",
    "    if question == \"stop\":\n",
    "        break\n",
    "\n",
    "    chat_messages.append({\"role\": \"user\", \"content\": question})\n",
    "    while True:\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        has_messages = False\n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c86b93de-a35e-444a-93ac-7e5537eab7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to do well in module 1?',\n",
       " 'text': '1. **Familiarize Yourself with Docker and Terraform**: Understanding the foundations of Docker and Terraform is key. Explore their official documentation and tutorials.\\n\\n2. **Install Required Libraries**: Ensure that any necessary libraries, like `psycopg2` for PostgreSQL, are correctly installed. Use:\\n   ```\\n   pip install psycopg2-binary\\n   ```\\n\\n3. **Practice Hands-On**: Implement concepts as you learn. Spin up Docker containers and use Terraform for configurations.\\n\\n4. **Check Your Code**:\\n   - If you encounter errors (like \"ModuleNotFoundError\"), double-check installations.\\n   - Ensure you\\'re running code in the correct environment (e.g., Jupyter notebook).\\n\\n5. **Engage with Peers**: Discuss questions within the course community or with classmates for better understanding.\\n\\n6. **Utilize Office Hours**: If available, attend office hours to clarify complex topics.\\n\\n7. **Review Past Lectures and Assignments**: Revisit materials to reinforce learning.\\n\\n8. **Stay Organized**: Keep notes and folders organized for easy reference when studying for assessments.',\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_search.index.docs[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
